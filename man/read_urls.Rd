% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/read_urls.R
\name{read_urls}
\alias{read_urls}
\title{Read content from URLs}
\usage{
read_urls(
  x,
  cores = 1,
  detect_boilerplate = TRUE,
  remove_boilerplate = TRUE,
  exclude_wiki_refs = TRUE
)
}
\arguments{
\item{x}{Character vector of URLs.}

\item{cores}{Number of cores for parallel requests (default 1).}

\item{detect_boilerplate}{Logical. Detect boilerplate (e.g. sign-up, related links).}

\item{remove_boilerplate}{Logical. If \code{detect_boilerplate} is \code{TRUE}, remove boilerplate rows; if \code{FALSE}, keep them and add \code{is_boilerplate}.}

\item{exclude_wiki_refs}{Logical. For Wikipedia URLs only, drop nodes whose \code{parent_heading} is References, See also, Bibliography, or Sources. Default \code{TRUE}.}
}
\value{
Data frame with \code{url}, \code{h1_title}, \code{date}, \code{type}, \code{node_id}, \code{parent_heading}, \code{text}, and optionally \code{is_boilerplate}.
}
\description{
Input: character vector of URLs. Output: structured data frame (one row per
node: headings, paragraphs, lists). Like \code{read_csv} or \code{read_html}:
bring an external resource into R. Follows \code{\link{fetch_urls}} or
\code{\link{fetch_wiki_urls}} in the pipelineâ€”fetch gets locations, read gets
text. Wikipedia uses high-fidelity selectors; use \code{parent_heading} to see
which section each node belongs to. External links and empty text rows are
omitted; optionally exclude References/See also/Bibliography/Sources sections for
wiki URLs.
}
\examples{
\dontrun{
urls <- fetch_urls("R programming", n_pages = 1)$url
nodes <- read_urls(urls[1:3], cores = 1)
}
}
