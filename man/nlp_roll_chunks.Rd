% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/nlp_roll_chunks.R
\name{nlp_roll_chunks}
\alias{nlp_roll_chunks}
\title{Roll units into fixed-size chunks with optional context}
\usage{
nlp_roll_chunks(corpus, by, chunk_size, context_size)
}
\arguments{
\item{corpus}{Data frame or data.table with a \code{text} column and the identifier columns specified in \code{by}.}

\item{by}{Character vector of identifier columns that define the text unit (e.g. \code{doc_id} or \code{c("url", "node_id")}). The last column is the level rolled into chunks (e.g. sentences).}

\item{chunk_size}{Integer. Number of units per chunk.}

\item{context_size}{Integer. Number of units of context around each chunk.}
}
\value{
Data.table with \code{chunk_id}, \code{chunk} (concatenated text), and \code{chunk_plus_context}.
}
\description{
Roll units (e.g. sentences) into fixed-size chunks with optional context
(RAG-style). Groups consecutive rows at the finest \code{by} level into chunks
and optionally adds surrounding context.
}
\examples{
corpus <- data.frame(doc_id = c('1', '1', '2'),
                    sentence_id = c('1', '2', '1'),
                    text = c("Hello world.",
                             "This is an example.",
                             "This is a party!"))
chunks <- nlp_roll_chunks(corpus, by = c('doc_id', 'sentence_id'),
                          chunk_size = 2, context_size = 1)
}
